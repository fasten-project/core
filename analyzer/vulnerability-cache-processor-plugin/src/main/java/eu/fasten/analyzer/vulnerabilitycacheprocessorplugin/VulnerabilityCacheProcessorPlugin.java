/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package eu.fasten.analyzer.vulnerabilitycacheprocessorplugin;

import eu.fasten.core.data.Constants;
import eu.fasten.core.data.DirectedGraph;
import eu.fasten.core.data.graphdb.RocksDao;
import eu.fasten.core.data.metadatadb.MetadataDao;
import eu.fasten.core.maven.GraphMavenResolver;
import eu.fasten.core.maven.data.Revision;
import eu.fasten.core.merge.CGMerger;
import eu.fasten.core.plugins.DataWriter;
import eu.fasten.core.plugins.DependencyGraphUser;
import eu.fasten.core.plugins.GraphDBReader;
import eu.fasten.core.plugins.KafkaPlugin;
import org.jooq.DSLContext;
import org.json.JSONArray;
import org.json.JSONObject;
import org.pf4j.Extension;
import org.pf4j.Plugin;
import org.pf4j.PluginWrapper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.sql.SQLException;
import java.sql.Timestamp;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Optional;
import java.util.Set;
import java.util.stream.Collectors;

public class VulnerabilityCacheProcessorPlugin extends Plugin {
    public VulnerabilityCacheProcessorPlugin(PluginWrapper wrapper) {
        super(wrapper);
    }

    @Extension
    public static class VulnerabilityCacheProcessorExtension implements KafkaPlugin, DependencyGraphUser, DataWriter, GraphDBReader {

        private final Logger logger = LoggerFactory.getLogger(VulnerabilityCacheProcessorExtension.class.getName());
        private String consumerTopic = "fasten.VulnerabilityCacheInvalidationExtension.out";

        private Exception pluginError = null;

        private static GraphMavenResolver graphResolver;
        private static String baseDir;

        private static DSLContext dbContext;
        private static MetadataDao kbDao;
        private static RocksDao graphDao;

        /**
         * The helper method that creates a graph resolver.
         * It first creates a Database Context from Knowledge Base and
         * then uses it to build dependency graph in the graph resolver.
         *
         * @param dbContext    - Connection to the database.
         * @param depGraphPath - the directory where the dependency graph can be found.
         */
        @Override
        public void loadGraphResolver(DSLContext dbContext, String depGraphPath) {
            logger.info("Building Dependency Graph from " + depGraphPath + "...");
            try {
                VulnerabilityCacheProcessorExtension.dbContext = dbContext;
                VulnerabilityCacheProcessorExtension.kbDao = new MetadataDao(dbContext);
                var graphResolver = new GraphMavenResolver();
                graphResolver.buildDependencyGraph(dbContext, depGraphPath);
                VulnerabilityCacheProcessorExtension.graphResolver = graphResolver;
            } catch (SQLException e) {
                var err = "Couldn't connect to the Knowledge Base";
                logger.error(err, e);
                this.setPluginError(new SQLException(err, e));
            } catch (RuntimeException e) {
                var err = "Couldn't connect to the Graph Database";
                logger.error(err, e);
                this.setPluginError(new RuntimeException(err, e));
            } catch (Exception e) {
                var err = "Couldn't build the Dependency Graph";
                logger.error(err, e);
                this.setPluginError(new RuntimeException(err, e));
            }
            logger.info("...Dependency Graph has been successfully built.");
        }

        /**
         * The helper method that creates a graph resolver.
         * It is overloaded method that allows to load graph resolver from the mocked instance.
         * Currently, used for testing purposes.
         *
         * @param dbContext      - Connection to the database.
         * @param kbDao          - Knowledge Base Dao.
         * @param graphDao       - Graph DB Dao.
         * @param graphResolver  - Graph Resolver.
         */
        public void loadGraphResolver(DSLContext dbContext, MetadataDao kbDao, RocksDao graphDao, GraphMavenResolver graphResolver) {
            VulnerabilityCacheProcessorExtension.dbContext = dbContext;
            VulnerabilityCacheProcessorExtension.kbDao = kbDao;
            VulnerabilityCacheProcessorExtension.graphDao = graphDao;
            VulnerabilityCacheProcessorExtension.graphResolver = graphResolver;
        }

        /**
         * Helper method that traverses the directed graph and creates paths from source to vulnerable dependency.
         *
         * @param graph           - directed graph of the dependencies.
         * @param source          - source artifact.
         * @param target          - target vulnerable dependency.
         * @param visited         - helper argument for graph traverse.
         * @param path            - helper argument for preliminary path.
         * @param vulnerablePaths - helper argument for preliminary vulnerable paths.
         * @return the list of paths for each vulnerable dependency.
         */
        private List<List<Long>> getPathsToVulnerableNode(DirectedGraph graph, long source, long target,
                                                          Set<Long> visited, List<Long> path, List<List<Long>> vulnerablePaths) {
            if (path.isEmpty()) {
                path.add(source);
            }
            if (source == target) {
                vulnerablePaths.add(new ArrayList<>(path));
                return vulnerablePaths;
            }
            visited.add(source);
            for (var node : graph.successors(source)) {
                if (!visited.contains(node)) {
                    path.add(node);
                    getPathsToVulnerableNode(graph, node, target, visited, path, vulnerablePaths);
                    path.remove(node);
                }
            }
            visited.remove(source);
            return vulnerablePaths;
        }

        @Override
        public void setRocksDao(RocksDao rocksDao) {
            VulnerabilityCacheProcessorExtension.graphDao = rocksDao;
        }

        @Override
        public void setBaseDir(String baseDir) {
            VulnerabilityCacheProcessorExtension.baseDir = baseDir;
        }

        @Override
        public String name() {
            return "Vulnerability Cache Processor Plugin";
        }

        @Override
        public String description() {
            return "Vulnerability Cache Processor Plugin. "
                    + "Consumes list MergeCacheInvalidationPlugin from Kafka"
                    + " topic and caches vulnerable paths to a file";
        }

        @Override
        public String version() {
            return "0.0.1";
        }

        @Override
        public void start() {
        }

        @Override
        public void stop() {
            graphDao.close();
            graphDao = null;
        }

        public void setPluginError(Exception throwable) {
            this.pluginError = throwable;
        }

        @Override
        public Exception getPluginError() {
            return this.pluginError;
        }

        @Override
        public void freeResource() {
            graphDao.close();
            graphDao = null;
        }

        @Override
        public Optional<List<String>> consumeTopic() {
            return Optional.of(Collections.singletonList(consumerTopic));
        }

        @Override
        public void setTopic(String topicName) {
            this.consumerTopic = topicName;
        }

        @Override
        public void consume(String record) {
            this.pluginError = null;

            // Parse JSON object from kafka topic of GraphDBExtension.
            // Although it doesn't have output payload, the plugin serializes the graph for its input.
            // And we can use the input copy from this topic and the serialized graph to process our caching.
            var json = new JSONObject(record);
            if (json.has("payload")) {
                if (json.get("payload").toString().isEmpty()) {
                    logger.error("Empty payload");
                    setPluginError(new RuntimeException("Empty payload"));
                    return;
                }
                json = json.getJSONObject("payload");
            }
            var artifacts = json.getJSONArray("artifacts");
            for (int i = 0; i < json.length(); i++) {
                var revisionObj = artifacts.getJSONObject(i);
                var id = revisionObj.optLong("id", -1);
                var groupId = revisionObj.getString("groupId");
                var artifactId = revisionObj.getString("artifactId");
                var version = revisionObj.getString("version");
                var timestamp = revisionObj.optLong("createdAt", -1);
                var revision = new Revision(id, groupId, artifactId, version, new Timestamp(timestamp));

                var depSet = graphResolver.resolveDependencies(revision, dbContext, true);
                var depIds = depSet.stream().map(r -> r.id).collect(Collectors.toSet());
                var vulnerableDependencies = kbDao.findVulnerablePackageVersions(depIds);
                var databaseMerger = new CGMerger(depIds, dbContext, graphDao);
                var graph = databaseMerger.mergeWithCHA(revision.product().toString() + Constants.mvnCoordinateSeparator + revision.version.toString());
                var vulnerabilities = kbDao.findVulnerableCallables(vulnerableDependencies, graph.nodes());
                var internalCallables = kbDao.getPackageInternalCallableIDs(revision.product().toString(), revision.version.toString());

                // Find all paths between any internal node and any vulnerable node in the graph
                var vulnerablePaths = new ArrayList<List<Long>>();
                for (var internal : internalCallables) {
                    for (var vulnerable : vulnerabilities.keySet()) {
                        vulnerablePaths.addAll(getPathsToVulnerableNode(graph, internal, vulnerable, new HashSet<>(), new ArrayList<>(), new ArrayList<>()));
                    }
                }

                // Group vulnerable path by the vulnerabilities
                var vulnerabilitiesMap = new HashMap<String, List<List<Long>>>();
                for (var path : vulnerablePaths) {
                    var pathVulnerabilities = vulnerabilities.get(path.get(path.size() - 1)).keySet();
                    for (var vulnerability : pathVulnerabilities) {
                        if (vulnerabilitiesMap.containsKey(vulnerability)) {
                            var paths = vulnerabilitiesMap.get(vulnerability);
                            var updatedPaths = new ArrayList<>(paths);
                            updatedPaths.add(path);
                            vulnerabilitiesMap.remove(vulnerability);
                            vulnerabilitiesMap.put(vulnerability, updatedPaths);
                        } else {
                            var paths = new ArrayList<List<Long>>();
                            paths.add(path);
                            vulnerabilitiesMap.put(vulnerability, paths);
                        }
                    }
                }

                var pathNodes = new HashSet<Long>();
                vulnerablePaths.forEach(pathNodes::addAll);
                var fastenUris = kbDao.getFullFastenUris(new ArrayList<>(pathNodes));

                // Generate JSON response
                var output = new JSONObject();
                for (var entry : vulnerabilitiesMap.entrySet()) {
                    var pathsJson = new JSONArray();
                    for (var path : entry.getValue()) {
                        var pathJson = new JSONArray();
                        for (var node : path) {
                            var jsonNode = new JSONObject();
                            jsonNode.put("id", node);
                            jsonNode.put("fasten_uri", fastenUris.get(node));
                            pathJson.put(jsonNode);
                        }
                        pathsJson.put(pathJson);
                    }
                    output.put(entry.getKey(), pathsJson);
                }

                // Write the output into the file
                try {
                    var firstLetter = revision.groupId.substring(0, 1);
                    var outputPath = baseDir + File.separator + firstLetter +
                            File.separator + revision.groupId +
                            File.separator + revision.artifactId +
                            File.separator + revision.version.toString() + ".json";

                    FileWriter outputFile = new FileWriter(outputPath);
                    outputFile.write(output.toString());
                } catch (IOException e) {
                    logger.error("Unable to persist the cache output in the file", e);
                    setPluginError(e);
                    return;
                }
            }

        }

        @Override
        public Optional<String> produce() {
            return Optional.empty();
        }

        @Override
        public String getOutputPath() {
            return null;
        }

    }
}

