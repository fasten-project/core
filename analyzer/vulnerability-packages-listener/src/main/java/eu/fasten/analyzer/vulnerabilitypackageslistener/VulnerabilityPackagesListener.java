/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package eu.fasten.analyzer.vulnerabilitypackageslistener;

import com.google.gson.Gson;
import eu.fasten.analyzer.vulnerabilitystatementsprocessor.VulnerabilityStatementsProcessor;
import eu.fasten.analyzer.vulnerabilitystatementsprocessor.db.MetadataUtility;
import eu.fasten.core.data.Constants;
import eu.fasten.core.data.vulnerability.Vulnerability;
import eu.fasten.core.plugins.DBConnector;
import eu.fasten.core.plugins.KafkaPlugin;
import org.jooq.DSLContext;
import org.json.JSONObject;
import org.pf4j.Extension;
import org.pf4j.Plugin;
import org.pf4j.PluginWrapper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.*;

public class VulnerabilityPackagesListener extends Plugin {

    public VulnerabilityPackagesListener(PluginWrapper wrapper) {
        super(wrapper);
    }

    @Extension
    public static class VulnerabilityPackagesKafkaPlugin implements KafkaPlugin, DBConnector {

        private static Map<String, DSLContext> contexts;
        private List<String> consumeTopics = new LinkedList<>(Collections.singletonList("fasten.CallableIndexFastenPlugin.out"));
        private Exception pluginError = null;
        private final Gson gson = new Gson();
        private final static Logger logger = LoggerFactory.getLogger("VulnerabilityPackagesKafkaPlugin");
        private final VulnerabilityStatementsProcessor.VulnerabilityStatementsKafkaPlugin statementsProcessor = new VulnerabilityStatementsProcessor.VulnerabilityStatementsKafkaPlugin();

        @Override
        public void setDBConnection(Map<String, DSLContext> dslContexts) {
            contexts = dslContexts;
            statementsProcessor.setDBConnection(contexts);
        }

        @Override
        public String name() {
            return "Vulnerability Packages Listener";
        }

        @Override
        public String description() {
            return "Listens to package updates from the (graph) database and triggers re-processing of vulnerabilties";
        }

        @Override
        public String version() {
            return "0.0.1";
        }

        @Override
        public void start() {
        }

        @Override
        public void stop() {
        }

        @Override
        public void setPluginError(Exception throwable) {
            this.pluginError = throwable;
        }

        @Override
        public Exception getPluginError() {
            return pluginError;
        }

        @Override
        public void freeResource() {
        }

        @Override
        public Optional<List<String>> consumeTopic() {
            return Optional.of(consumeTopics);
        }

        @Override
        public void setTopics(List<String> consumeTopics) {
            this.consumeTopics = consumeTopics;
        }

        @Override
        public void consume(String record) {
            setPluginError(null);
            try {
                var metadataUtility = new MetadataUtility();
                var jsonRecord = new JSONObject(record);
                var payload = (JSONObject) jsonRecord.query("/input/input/input/payload");
                var ecosystem = payload.getString("forge");
                var context = findContextForEcosystem(ecosystem);
                var packageName = getPackageName(payload);
                var version = payload.getString("version");
                logger.info("Processing package update for forge \"" + ecosystem + "\": " + packageName + ":" + version);
                var vulnerabilities = metadataUtility.getVulnerabilitiesForPurl(ecosystem, packageName, version, context);
                logger.info("Found the following vulnerabilities for " + packageName + ":" + version + ": " + vulnerabilities.toString());
                if(vulnerabilities.size() > 0) {
                    vulnerabilities.forEach(v -> {
                        var statement = metadataUtility.getVulnerabilityStatement(v, context);
                        var statementJson = gson.fromJson(statement, Vulnerability.class);
                        statementsProcessor.injectVulnerabilityIntoDB(statementJson, metadataUtility);
                    });
                }
            }
            catch (Exception e) {
                var error = "Error processing package update: " + e;
                logger.error(error);
                setPluginError(e);
            }
        }

        private DSLContext findContextForEcosystem(String ecosystem) {
            var context = ecosystem.equals("") ? null : contexts.get(ecosystem);
            if (context == null) {
                throw new UnsupportedOperationException("Malformed ecosystem data or unsupported ecosystem \"" + ecosystem + "\"");
            }
            return context;
        }

        private String getPackageName(JSONObject payload) {
            var ecosystem = payload.getString("forge");
            switch(ecosystem) {
                case Constants.mvnForge: return payload.getString("groupId") + Constants.mvnCoordinateSeparator + payload.getString("artifactId");
                case Constants.debianForge:
                case Constants.pypiForge:
                    return payload.getString("product");
                default: throw new UnsupportedOperationException("Unsupported forge: \"" + ecosystem + "\"");
            }
        }

        @Override
        public Optional<String> produce() {

            return Optional.empty();
        }

        @Override
        public String getOutputPath() {
            return null;
        }
    }
}
